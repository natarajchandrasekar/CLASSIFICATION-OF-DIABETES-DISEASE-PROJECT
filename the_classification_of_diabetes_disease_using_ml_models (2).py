# -*- coding: utf-8 -*-
"""The Classification of Diabetes Disease using ML Models

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rPxEHw52nh0mfjg3ymfbYjqvyuRWbIZI

## CLASSIFICATION OF DIABETES DISEASE BY USING LOGISTIC REGRESSION , GAUSSIAN NAIVE BAYES , DECISION TREE , SUPPORT VECTOR MACHINE AND NEURAL NETWORKS

# Import Dataset :
"""

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'diabetes-prediction-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3102947%2F5344155%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240424%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240424T180618Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7c7417100cca8a4f764550c3a9ce92eb8db192157e95e3f58f0b659c8a2f079321e3b539bb116505645af6943ebc76611620850e98e0e3d33893fffed2f4c02fd4fd194513acfdb049a6f2d59ffdf103c6b7f68ee4079cea2a333528963417eb5399a0cc2c6699e435ec8c8d8721dbcbb139582f9be439450f7c430b1e798888718e0384983b2a548df2ed9347dcb071f39652bdcd87bb258ed57a5b68e98c6ec170667cbcc72afa409d536bc74b6d417472a6d4ffa3faca61d724db1bb29246a89e1d15bcc970f559eeb1b78496ed02afd5dc386f5f3bd6433cb27400775adcbf9d5904f3c0a957607e4ae98023f671eb06e5ac7695585b2b68ab907f771217'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""<br>
<h1 style = "font-size:50px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #23aa80; text-align: center; border-radius: 100px 100px;"><b>CLASSIFICATION OF DIABETES DISEASE :</b>  Model Selection and Model Accuracy </h1>
<br>

<br>
<h1 style = "font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #1e9570; text-align: center; border-radius: 100px 100px;">Diabetes Prediction</h1>
<br>

<!-- <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAACfCAMAAABX0UX9AAAAe1BMVEUAAAD///93d3dxcXEfHx98fHyMjIyCgoKTk5Pt7e2goKD09PSFhYUiIiJ/f3/p6em0tLSmpqbJycni4uJVVVViYmKwsLA8PDzc3NwmJiYtLS3W1tYzMzMbGxtISEj39/ehoaHExMSYmJhBQUEMDAxmZmbFxcVaWloLCwtmYPo6AAAEDElEQVR4nO3ZC3eiOhDAcdD6wgcIFRWsivWx3/8TLjNJAF27671ntZd7/r9zug0hYhkzmch6HgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB8j8iv9b77j2mdaSN6fue7/5rWiX4Xvo83NT163lvNnlx2gmC2bQ7fzoL94L3ZM5VXa2NqfrurVgdlc+q11qcfjr8M34fr73teWA1a6blTYo5GEzd6MDI9u3l1ga52nDzzKQ1t7046bczey2b0zBt8rqP89F0Eb8JXzcwyfKMqfMnVKd+PbwbbESLWw3PZ2tbdS+0cmIO0bF6efZNPF90L37qKxy+zT8cnUZT7bvZ0NJLzfdGIqGdfIU0J/0Y7J9pXmBHlBzd6zS0+VXAnfD/034EJX2nou9p8qgZL8vmyAEogF9KzlkAtddhMImlHyhsctLcwSa/tRdmqc73F8jvJq67DN9PWqmzZNU/mUuo1p1G3WubKa46z8ij3ZJF12WtXikzaMos/n3ZPL7T9B+HL/EbKzedzOT2u5pyXZZlW5zdNbMl6mceJHbBsTEl5VeL9L4SPh29yJ+V09sbD5kZmqGXhYF8vR3vPZLSrt5cqo1uveDx8QRVHQxbERVV2U7fzS3SOrm3Wyv48NO8zlkIi01dy9+Ppd/YS6ePhS10NsREbS3tWlWY/103d0q6KkrWSzLnJ3pFU3cIsfr7bRbZf9O/DZ9bBH8N81+wIbFnol78Dz6V8plVHLtrVAt5/wa29wurx8B1cbY2iKA2bO7fNINL9tQyTxbSsK/PIZq2nce3pHDQzs7BVpZU2V0frm8qbh2Gujcmv4TvZzYgyK9yx/k47N0m79ZukpEi9zcpg7jwtuaHEM/Za6vN6t5/ehE8mY3VC98ONfZ9f71K2Jlff6zxcmrKaXoVPCrVsCPeJCZkWqi/meyucdUFy9HtE82bmLh6ynh21q1+NKFw+mhQdmacLtkeifND5NQ7myq2G5aXG9rJyrbH7hFpo4ze3XHbb0QifJnNw6SY2w6I4luYqjlOzb/Z3h8XisHOVQjIznLxvT/p1eKPTcW+vJTVXngsU5l3c5tk3TxNa6Sx/fW52uZl7WtJMpaDOvLV3+8SlW5/MTfiOjedeMq+jOr91qsku2XxIO+0zRXrxuhv+q+yn74/OaZFUt321Ern4jfRLaR0d/ZZ1seEM17Hd933k1QjJzjqZ7XNDaWjMTNExz7Jec7N/39m/53ohz4I4WUW2rzvrGbOu6ehEeR6V7cWsZ4dsg/MqzKOBrJTrQW9WP3fu9noT2TlfyovYB9RbabZ98v02fPhKfj98/E/bQ46d7j2dzZ9fCgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOA/4CcgHyoagKr9FwAAAABJRU5ErkJggg==" width="500" height="600"> -->



<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">

* **Objective:** The objective of this project is to develop a robust model for predicting the likelihood of diabetes in patients based on their medical history and demographic information. Such predictions can be immensely valuable for healthcare professionals in identifying individuals who may be at risk of developing diabetes. Furthermore, pharmaceutical companies are also interested in these predictions as they can aid in customer profiling and developing tailored treatment plans.

    
* **Dataset:** The dataset used for this project is the Diabetes Prediction Dataset, which comprises a comprehensive collection of medical and demographic data from patients, along with their diabetes status (positive or negative). The dataset encompasses several essential features including age, gender, body mass index (BMI), hypertension, heart disease, smoking history, HbA1c level, and blood glucose level.

    
* **Methodology:** In this project, we will focus on comparing the accuracy scores of various models to identify the most effective model for predicting diabetes. By leveraging the dataset's predictors, we will construct and evaluate multiple models, each employing different algorithms or techniques. The performance of these models will be assessed based on their accuracy in predicting diabetes.
    

* **Significance:** The implications of accurately predicting diabetes are substantial for both healthcare professionals and pharmaceutical companies. For healthcare professionals, these predictions can assist in early identification of individuals at risk of diabetes, facilitating the implementation of preventive measures and personalized treatment plans. Pharmaceutical companies can leverage such predictions for customer profiling, enabling targeted marketing efforts and tailored interventions.

# <span><h1 style = "font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px; text-align:center">Install Required Libraries</h1></span> <a class='anchor' id='install'></a>
"""

!pip install scikit-optimize

"""# <span><h1 style = "font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px; text-align:center">Import Required Libraries üìö</h1></span>  <a class='anchor' id='import'></a>


<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">

Import the required libraries and modules into the notebook. These libraries provide essential functionalities for data analysis and modeling, such as data manipulation, visualization, and machine learning algorithms.
"""

import time
import pandas as pd
import numpy as np
import scipy as sp
import scipy.stats as stats
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import sklearn.model_selection
from sklearn.manifold import TSNE

from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import SGDClassifier


from skopt import gp_minimize
from skopt.space import Real, Integer
from skopt.utils import use_named_args
from skopt.plots import plot_convergence

import seaborn as sns
sns.set_style("darkgrid")

import warnings
warnings.filterwarnings("ignore")

"""# <span><h1 style = "font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px; text-align:center">Exploratory Data Analysis (EDA) üîç</h1></span> <a class='anchor' id='eda'></a>

<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">

Performing exploratory data analysis to gain insights into the dataset. Through data visualization and statistical summaries, we explore the distributions, relationships, and characteristics of the variables. EDA helps us understand the data better and identify any patterns or trends that may exist.

# <span><h1 style = "font-family: garamond; font-size: 30px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px; text-align:center">Data Cleaning üßπ</h1></span> <a class='anchor' id='clean'></a>

<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">

* Data cleaning is a critical step in the data preprocessing phase. It involves handling missing values, removing duplicates, and addressing inconsistencies or errors present in the dataset. By ensuring the cleanliness and reliability of the data, we significantly reduce the likelihood of biased or inaccurate analysis.
   

* Data cleaning plays a pivotal role in achieving "tidy data," which is essential for conducting further operations and analyses effectively. In this section, we will meticulously analyze the data types of variables and correct them if necessary. Additionally, we will identify and handle null values in the dataset.
    

* Regarding null values, we will adopt a thoughtful approach. For predictors with less than 5% of missing values, we will impute those missing values using appropriate techniques such as mean, median, or mode. However, for predictors with a high proportion of missing values, we will carefully consider their impact on the analysis. In such cases, if we determine that the predictor is still crucial for our analysis, we may revisit the data cleaning step to explore alternative approaches.

    
* By adhering to robust data cleaning practices, we ensure that the dataset is in optimal condition for subsequent analysis and modeling.
"""

df = pd.read_csv('/content/diabetes_prediction_dataset.csv')

df.head()

df.shape

df.dtypes

df.isna().sum()

"""<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>  Insights:</font></h3>

* After examining the default data types, we made necessary adjustments to ensure that predictors such as age and blood_glucose_level are accurately represented. These adjustments were made to facilitate proper analysis and interpretation of these important variables.
    

* Additionally, we conducted a preliminary check for null values in the dataset. Identifying and addressing null values is crucial for maintaining data integrity and reliability. By assessing the presence of missing values, we can take appropriate measures to handle them effectively during the data cleaning process.
"""

df['age'] = df['age'].astype(int)

df['smoking_history'].value_counts()

df['gender'].value_counts()

"""<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'> Insights:</font></h3>

* Upon further examination of the dataset, particularly focusing on the object types, we have identified a significant number of rows (35,816) where the smoking_history predictor is labeled as "No info." While "No info" can be considered as a dimension of information, it is not possible to impute or fill in this missing information when it constitutes more than 30% of the observations.

    
* It is important to note that if healthcare experts consider smoking_history to be an essential predictor, there is a need to improve the data collection method to ensure proper capture of this information. Collecting accurate and complete data is crucial for reliable analysis and meaningful insights.

    
* Given the high proportion of "No info" values in the smoking_history predictor, it is advisable to remove this predictor from the analysis. This decision is based on the consideration that a predictor with such a high percentage of missing values may introduce bias or inaccuracies into the analysis if imputation methods are employed.

    
* By carefully evaluating the presence of "No info" values and making informed decisions regarding predictors with high missing value proportions, we aim to maintain the integrity and quality of the dataset, enabling more reliable analysis and accurate interpretations.
"""

df = df.drop(columns = 'smoking_history')

df.describe()

df['blood_glucose_level'] =  df['blood_glucose_level'].astype(float)

df.dtypes

"""<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'> Insights:</font></h3>

The Data Cleaning process for the Diabetes Prediction Dataset has been completed. Below are the final columns and their corresponding data types after the necessary adjustments:


* **Age:** This discrete variable has been converted into an integer type to accurately represent the age values.

   
* **Blood_glucose_level:** As a continuous variable, it has been converted into a float type to accurately represent the decimal values associated with blood glucose levels.

By appropriately adjusting the data types for these variables, we ensure that they are represented in a format that aligns with their nature and supports further analysis and modeling tasks.

# <span><h1 style = "font-family: garamond; font-size: 30px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px; text-align:center">Data Visualization üìä</h1></span> <a class='anchor' id='visualize'></a>



<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>Insights:</font></h3>

Utilize data visualization techniques to visually explore and communicate insights from the Diabetes Prediction Dataset. By creating meaningful and informative visual representations such as plots, charts, and graphs, we aim to uncover patterns, relationships, and trends within the data. Data visualization enhances our understanding of the dataset, making it easier to convey findings and key messages to stakeholders and decision-makers. Through effective visualizations, we can highlight important patterns and correlations, enabling better-informed decision-making and actionable insights.
"""

df.describe()

sns.catplot(data = df, x = 'diabetes', y = 'blood_glucose_level', kind = 'box', hue = 'gender')
plt.show()

"""<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>Insights:</font></h3>

* The Box Plot for Diabetes vs. Blood Glucose Level appears to be similar across all genders. However, upon initial observation, the plot for the "Other" gender category appears different. It is important to note that this discrepancy may be attributed to the limited sample size, as there were only 18 entries available for this gender category in the dataset.

    
* This finding suggests that further analysis and interpretation of the Box Plot should be conducted with caution, taking into account the potential bias introduced by the small sample size. It is crucial to consider the representativeness and statistical significance of the available data when drawing conclusions about the relationship between diabetes and blood glucose level for the "Other" gender category.

    
* By recognizing the limitations imposed by the small sample size, we can ensure that our analysis remains objective and avoids making generalizations based on insufficient data.
"""

sns.catplot(data = df, x = 'diabetes', y = 'age', kind = 'box', hue = 'gender')
plt.show()

"""<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>Insights:</font></h3>

* The Box Plot for Diabetes vs. Age reveals that individuals with diabetes tend to have a higher median age compared to those without diabetes. Moreover, the plot indicates a general trend of increasing age among individuals with diabetes, with a few outliers where diabetes is observed in individuals under the age of 20.

    
* This finding highlights the association between higher age and the likelihood of developing diabetes. It suggests that age plays a significant role in the prevalence of diabetes, with older individuals being more susceptible to the condition. The presence of outliers below the age of 20 may indicate cases of early-onset diabetes or other factors contributing to diabetes at a younger age.

    
* By considering the distribution of ages and the presence of outliers, we can better understand the relationship between age and diabetes. This insight can inform healthcare professionals and researchers in identifying age-related risk factors and designing targeted interventions to address diabetes in different age groups.
"""

sns.catplot(data = df, x = 'hypertension', y = 'age', kind = 'box', hue = 'gender')
plt.show()

"""<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'> Insights:</font></h3>

* The Box Plot for Hypertension vs. Age, categorized by gender, shows a similarity to the previously observed Diabetes vs. Age plot. This similarity was expected, as there is a natural correlation between age and the likelihood of developing both diabetes and hypertension. Age can be considered a confounding factor in this context.

    
    
* The resemblance in the boxplots reinforces the notion that as age increases, the likelihood of developing hypertension also tends to increase. This aligns with the general understanding that age is a significant risk factor for hypertension.
"""

sns.relplot(data = df, x = 'HbA1c_level', y =  'blood_glucose_level', kind = 'line', hue = 'gender', ci = None, markers = True)
plt.show()

"""<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>Insights:</font></h3>

* The comparison of HbA1c level and blood glucose level between male and female genders reveals a similarity in their distributions. Both genders appear to exhibit similar patterns and ranges of values for these predictors. However, it is important to note that the "Other" gender category appears to have a different shape in the distribution. This discrepancy, however, may be attributed to the limited number of observations available for this gender category, as only 18 entries were recorded.

    
* Considering the limited sample size for the "Other" gender category, caution should be exercised when interpreting the distribution and drawing conclusions. The small number of observations may lead to an inaccurate representation of the actual population. Therefore, it is essential to approach the analysis of this category with prudence, taking into account the potential bias introduced by the limited data.
"""

sns.relplot(data = df, x = 'blood_glucose_level', y =  'bmi', kind = 'line', hue = 'gender', ci = None)
plt.show()

"""# <span><h1 style = "font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px; text-align:center">Preparing Data for Modelling :</h1></span> <a class='anchor' id='data'></a>

<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
    
This section focuses on preparing the data for machine learning modeling. It involves various preprocessing steps such as feature scaling, encoding categorical variables, and splitting the data into training and testing sets. Properly preparing the data ensures it is in a suitable format for training and evaluating machine learning models.
"""

design_matrix = df.iloc[:,:-1]
design_matrix = pd.get_dummies(design_matrix, columns= ['gender'], drop_first=True)
response_y = df.iloc[:,-1]

design_matrix

response_y

X_train, X_test, y_train, y_test = train_test_split(design_matrix, response_y, test_size = 0.2, random_state = 110)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

"""<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>Insights:</font></h3>
    
* Now that we have prepared our training and testing datasets, we can proceed with evaluating the performance of multiple machine learning classifiers. During this evaluation, we will assess various metrics such as accuracy, precision, recall, F1 score, and training time for each classifier. This comparative analysis will allow us to determine the effectiveness and efficiency of different classifiers in predicting diabetes based on the provided dataset.

    
* By systematically evaluating the performance metrics of each classifier, we can gain insights into their strengths and weaknesses. This information will aid in selecting the most suitable classifier for our specific task of diabetes prediction. Additionally, comparing the metrics across different classifiers will provide valuable information for making informed decisions and optimizing our modeling approach.

    
* The performance metrics, including accuracy, precision, recall, F1 score, and training time, will be recorded and analyzed to identify the classifier that achieves the best overall performance. This process will contribute to the selection of a robust and accurate model for predicting diabetes in the given dataset.

# <span><h1 style = "font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px; text-align:center">Evaluating ML Classifiers üìä</h1></span> <a class='anchor' id='ml'></a>

<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
    
Evaluate the performance of various machine learning classifiers on the dataset. We assess metrics such as accuracy, precision, recall, and F1-score to determine how well each model predicts diabetes. By comparing the results, we can identify the models that perform the best on our dataset.
"""

# Define a dictionary to store the results
results = {}

"""## <span><h1 style = "font-family: garamond; font-size: 30px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px">1. Logistic Regression</h1></span> <a class='anchor' id='clean'></a>


<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>üí° About Model:</font></h3>
    
A linear classifier that models the probability of the target class using a logistic function. It's a simple yet effective method that works well when the classes are linearly separable. It's also easy to interpret the coefficients of the logistic regression model.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# start_time = time.time()
# logistic = LogisticRegression()
# logistic.fit(X_train, y_train)
# y_pred = logistic.predict(X_test)
# 
# end_time = time.time()
# training_time = end_time - start_time
# 
# results['Logistic Regression'] = [accuracy_score(y_test, y_pred),
#                                   precision_score(y_test, y_pred, average='weighted'),
#                                   recall_score(y_test, y_pred, average='weighted'),
#                                   f1_score(y_test, y_pred, average='weighted'),
#                                   training_time]
#

"""## <span><h1 style = "font-family: garamond; font-size: 30px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px">2. Gaussian Naive Bayes (GaussianNB)</h1></span> <a class='anchor' id='clean'></a>

<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>About Model:</font></h3>
    
    
A probabilistic classifier that models the joint distribution of the features and the target class using Bayes' theorem and the assumption that the features are conditionally independent given the target class. It's a simple and fast method that works well for text classification and other high-dimensional problems.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# start_time = time.time()
# gnb = GaussianNB()
# gnb.fit(X_train, y_train)
# y_pred = gnb.predict(X_test)
# 
# end_time = time.time()
# training_time = end_time - start_time
# 
# results['GaussianNB'] = [accuracy_score(y_test, y_pred),
#                                   precision_score(y_test, y_pred, average='weighted'),
#                                   recall_score(y_test, y_pred, average='weighted'),
#                                   f1_score(y_test, y_pred, average='weighted'),
#                                   training_time]
#

"""## <span><h1 style = "font-family: garamond; font-size: 30px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px">3. Decision Trees</h1></span> <a class='anchor' id='clean'></a>


<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>About Model:</font></h3>
    
    
A non-parametric classifier that models the decision rules as a tree. It's a powerful method that works well for both classification and regression problems. It's also easy to interpret the decision rules and the importance of the features.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# start_time = time.time()
# dt = DecisionTreeClassifier()
# dt.fit(X_train, y_train)
# y_pred = dt.predict(X_test)
# 
# end_time = time.time()
# training_time = end_time - start_time
# 
# results['Decision Trees'] = [accuracy_score(y_test, y_pred),
#                                   precision_score(y_test, y_pred, average='weighted'),
#                                   recall_score(y_test, y_pred, average='weighted'),
#                                   f1_score(y_test, y_pred, average='weighted'),
#                                   training_time]
#

"""## <span><h1 style = "font-family: garamond; font-size: 30px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px">4. Support Vector Machines (SVM)</h1></span> <a class='anchor' id='clean'></a>

<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'> About Model:</font></h3>
    
    
A linear or non-linear classifier that finds the hyperplane that maximizes the margin between the classes. It's a powerful method that works well for both linearly and non-linearly separable problems. It's also less prone to overfitting than other methods.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# start_time = time.time()
# svm = SVC()
# svm.fit(X_train, y_train)
# y_pred = svm.predict(X_test)
# 
# end_time = time.time()
# training_time = end_time - start_time
# 
# results['Support Vector Machines'] = [accuracy_score(y_test, y_pred),
#                                   precision_score(y_test, y_pred, average='weighted'),
#                                   recall_score(y_test, y_pred, average='weighted'),
#                                   f1_score(y_test, y_pred, average='weighted'),
#                                   training_time]
#

"""## <span><h1 style = "font-family: garamond; font-size: 30px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px">5. Neural Networks (Multi-layer Perceptron)</h1></span> <a class='anchor' id='clean'></a>


<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'>About Model:</font></h3>
    
    
A flexible and powerful method that uses multiple layers of interconnected neurons to learn complex relationships between the features and the target class. It's a state-of-the-art method that works well for a wide range of problems, including image recognition, natural language processing, and speech recognition.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# start_time = time.time()
# mlp = MLPClassifier()
# mlp.fit(X_train, y_train)
# y_pred = mlp.predict(X_test)
# 
# end_time = time.time()
# training_time = end_time - start_time
# 
# results['Neural Networks (Multi-layer Perceptron)'] = [accuracy_score(y_test, y_pred),
#                                   precision_score(y_test, y_pred, average='weighted'),
#                                   recall_score(y_test, y_pred, average='weighted'),
#                                   f1_score(y_test, y_pred, average='weighted'),
#                                   training_time]

"""# <span><h1 style = "font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#1e9570; border-radius: 100px 100px; text-align:center">Model Result Comparison üìà</h1></span> <a class='anchor' id='result'></a>

<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">

    
Compare the results and performance of different machine learning models. We analyze the accuracy and other relevant metrics to determine the most effective model for predicting diabetes. This comparison helps us choose the model that provides the highest predictive accuracy and reliability.
"""

# Create a DataFrame from the results
df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time'])

df_results

# @title Accuracy

from matplotlib import pyplot as plt
df_results['Accuracy'].plot(kind='hist', bins=20, title='Accuracy')
plt.gca().spines[['top', 'right',]].set_visible(False)

"""

<div style="border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #f6f5f5; font-size:100%; text-align:left">
<h3 align="left"><font color='#DEB887'> Final Verdict:</font></h3>
    

* The Result Dataframe provides scores, time taken, precision, recall, and F1 values for each tested model. The scores indicate the accuracy achieved on the test dataset. The time taken represents the duration of one iteration for each model, with more complex models typically requiring more time.

    
* The F1 score serves as a combined measure of precision and recall. A higher F1 score implies better performance in terms of both metrics, making it an optimal criterion for model evaluation.

"""